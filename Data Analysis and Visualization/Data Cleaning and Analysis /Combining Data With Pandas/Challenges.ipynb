{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Cleaning and Analysis\n",
    "## Combining Data with Pandas\n",
    "\n",
    "| pd.concat()                                                             \t| pd.merge()                                                                                                   \t| Key                                                                                                                                                                                                               \t|\n",
    "|-------------------------------------------------------------------------\t|--------------------------------------------------------------------------------------------------------------\t|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| Default Join Type                                                       \t| Outer                                                                                                        \t| Inner                                                                                                                                                                                                             \t|\n",
    "| Can Combine More Than Two Dataframes at a Time?                         \t| Yes                                                                                                          \t| No                                                                                                                                                                                                                \t|\n",
    "| Can Combine Dataframes Vertically<br>(axis=0) or Horizontally (axis=1)? \t| Both                                                                                                         \t| Horizontally                                                                                                                                                                                                      \t|\n",
    "| Syntax                                                                  \t| Concat (Vertically)<br>concat([df1,df2,df3])<br><br>Concat (Horizontally)<br>concat([df1,df2,df3], axis = 1) \t| Merge (Join on Columns)<br>merge(left = df1, right = df2, how = 'join_type', on = 'Col')<br><br>Merge (Join on Index)<br>merge(left = df1, right = df2, how = 'join_type', left_index = True, right_index = True) \t|\n",
    "\n",
    "In the last exercise, we confirmed that the mean world happiness score stayed approximately the same from 2015 to 2017.\n",
    "\n",
    "In this mission, we learned how to combine data using the pd.concat() and pd.merge() functions. In your travels with pandas, you may happen upon the df.append() and df.join() methods, which are basically shortcuts for the concat() and merge() functions. We didn't cover them in this mission, as the differences are few, but if you want to learn more about them, check out this documentation.\n",
    "\n",
    "As we saw in the last screen, in order to perform more complex analysis, we have to be able to clean and manipulate data, whether it be adding data to a dataframe or renaming a column. In the next mission, we'll continue building on what we've learned so far as we learn ways to transform and reshape our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.562348Z",
     "start_time": "2021-01-01T10:12:32.223444Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Stylistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.567832Z",
     "start_time": "2021-01-01T10:12:32.563650Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use(\"dark_background\")\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_column\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.641155Z",
     "start_time": "2021-01-01T10:12:32.570120Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "happiness2015 = pd.read_csv(\"../datasets/World_Happiness_2015.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Introduction\n",
    "We've already read the World_Happiness_2015.csv file into a dataframe called happiness2015.\n",
    "\n",
    "- Use the pandas.read_csv() function to read the World_Happiness_2016.csv file into a dataframe called happiness2016 and the World_Happiness_2017.csv file into a dataframe called happiness2017.\n",
    "- Add a column called Year to each dataframe with the corresponding year. For example, the Year column in happiness2015 should contain the value 2015 for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.785103Z",
     "start_time": "2021-01-01T10:12:32.642629Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../World_Happiness_2016.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-66ccbaa81e42>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mhappiness2016\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"../World_Happiness_2016.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mhappiness2017\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"../World_Happiness_2017.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0myear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2015\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2016\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2017\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mhappiness2015\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhappiness2016\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhappiness2017\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Year\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0myear\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    686\u001B[0m     )\n\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 688\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    689\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 454\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    946\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    947\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 948\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    949\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    950\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1178\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1179\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1180\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1181\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1182\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   2008\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2009\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2010\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2011\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2012\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../World_Happiness_2016.csv'"
     ]
    }
   ],
   "source": [
    "happiness2016 = pd.read_csv(\"../World_Happiness_2016.csv\")\n",
    "happiness2017 = pd.read_csv(\"../World_Happiness_2017.csv\")\n",
    "\n",
    "for year, dataset in zip([2015, 2016, 2017], [happiness2015, happiness2016, happiness2017]):\n",
    "    dataset[\"Year\"] = year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combining Dataframes with the Concat Function\n",
    "We've already saved the subsets from happiness2015 and happiness2016 to the variables head_2015 and head_2016.\n",
    "\n",
    "- Use the pd.concat() function to combine head_2015 and head_2016 along axis = 0. Remember to pass the head_2015 and head_2016 into the function as a list. Assign the result to concat_axis0.\n",
    "- Use the pd.concat() function to combine head_2015 and head_2016 along axis = 1. Remember to pass head_2015 and head_2016 into the function as a list and set the axis parameter equal to 1. Assign the result to concat_axis1.\n",
    "- Use the variable inspector to view concat_axis0 and concat_axis1.\n",
    "    - Assign the number of rows in concat_axis0 to a variable called question1.\n",
    "    - Assign the number of rows in concat_axis1 to a variable called question2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.787046Z",
     "start_time": "2021-01-01T10:12:32.227Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head_2015 = happiness2015[['Country','Happiness Score', 'Year']].head(3)\n",
    "head_2016 = happiness2016[['Country','Happiness Score', 'Year']].head(3)\n",
    "\n",
    "concat_axis0 = pd.concat([head_2015, head_2016])\n",
    "concat_axis1 = pd.concat([head_2015, head_2016], axis=1)\n",
    "\n",
    "question1 = concat_axis0.shape[0]\n",
    "concat_axis2 = concat_axis1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combining Dataframes with the Concat Function Continued\n",
    "We've already created the head_2015 and head_2016 variables.\n",
    "\n",
    "- Use the pd.concat() function to combine head_2015 and head_2016 along axis = 0. Remember to pass the head_2015 and head_2016 into the function as a list. Assign the result to concat_axis0.\n",
    "- Use the variable inspector to view concat_axis0.\n",
    "    - Assign the number of rows in concat_axis0 to a variable called rows.\n",
    "    - Assign the number of columns in concat_axis0 to a variable called columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.788097Z",
     "start_time": "2021-01-01T10:12:32.228Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head_2015 = happiness2015[['Year','Country','Happiness Score', 'Standard Error']].head(4)\n",
    "head_2016 = happiness2016[['Country','Happiness Score', 'Year']].head(3)\n",
    "\n",
    "concat_axis0 = pd.concat([head_2015, head_2016])\n",
    "\n",
    "rows = concat_axis0.shape[0]\n",
    "columns = concat_axis0.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combining Dataframes with Different Shapes Using the Concat Function\n",
    "- Use the pd.concat() function to combine head_2015 and head_2016 along axis = 0 again. This time, however, set the ignore_index parameter to True to reset the index in the result. Assign the result to concat_update_index.\n",
    "    - Use the variable inspector to view the results and confirm the index was reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.788981Z",
     "start_time": "2021-01-01T10:12:32.230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head_2015 = happiness2015[['Year','Country','Happiness Score', 'Standard Error']].head(4)\n",
    "head_2016 = happiness2016[['Country','Happiness Score', 'Year']].head(3)\n",
    "\n",
    "concat_update_index = pd.concat([head_2015, head_2016], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Joining Dataframes with the Merge Function\n",
    "We've already saved three rows from happiness2015 and happiness2016 to variables named three_2015 and three_2016.\n",
    "\n",
    "- Use the pd.merge() function to join three_2015 and three_2016 on the Country column. Assign the result to merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.790375Z",
     "start_time": "2021-01-01T10:12:32.232Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "three_2015 = happiness2015[['Country','Happiness Rank','Year']].iloc[2:5]\n",
    "three_2016 = happiness2016[['Country','Happiness Rank','Year']].iloc[2:5]\n",
    "\n",
    "merged = pd.merge(left=three_2015, right=three_2016, on=\"Country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Joining on Columns with the Merge Function\n",
    "\n",
    "There are actually four different types of joins:\n",
    "\n",
    "1. Inner: only includes elements that appear in both dataframes with a common key\n",
    "2. Outer: includes all data from both dataframes\n",
    "3. Left: includes all of the rows from the \"left\" dataframe along with any rows from the \"right\" dataframe with a common key; the result retains all columns from both of the original dataframes\n",
    "4. Right: includes all of the rows from the \"right\" dataframe along with any rows from the \"left\" dataframe with a common key; the result retains all columns from both of the original dataframes\n",
    "- Update merged to use a left join instead of an inner join. Set the how parameter to 'left' in merge(). Assign the result to merged_left.\n",
    "- Update merged_left so that the left parameter equals three_2016 and the right parameter equals three_2015. Assign the result to merged_left_updated.\n",
    "- Based on the results of this exercise, when using a left join, does changing the dataframe assigned to the left and right parameters change the result? Try to answer this question before moving onto the next screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.791638Z",
     "start_time": "2021-01-01T10:12:32.233Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "three_2015 = happiness2015[['Country','Happiness Rank','Year']].iloc[2:5]\n",
    "three_2016 = happiness2016[['Country','Happiness Rank','Year']].iloc[2:5]\n",
    "merged = pd.merge(left=three_2015, right=three_2016, on='Country')\n",
    "\n",
    "merged_left = pd.merge(left=three_2015, right=three_2016, on='Country', how=\"left\")\n",
    "merged_left_updated = pd.merge(left=three_2016, right=three_2015, on='Country', how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Left Joins with the Merge Function\n",
    "- Update merged to use the suffixes _2015 and _2016. Set the suffixes parameter to ('_2015', '_2016') in merge(). Assign the result to merged_suffixes.\n",
    "- Update merged_updated to use the suffixes _2015 and _2016. Notice that the \"left\" dataframe is three_2016 and the \"right\" dataframe is three_2015. Assign the result to merged_updated_suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.793050Z",
     "start_time": "2021-01-01T10:12:32.235Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "three_2015 = happiness2015[['Country','Happiness Rank','Year']].iloc[2:5]\n",
    "three_2016 = happiness2016[['Country','Happiness Rank','Year']].iloc[2:5]\n",
    "merged = pd.merge(left=three_2015, right=three_2016, how='left', on='Country')\n",
    "merged_updated = pd.merge(left=three_2016, right=three_2015, how = 'left', on='Country')\n",
    "\n",
    "merged_suffixes = pd.merge(left=three_2015, right=three_2016, how='left', on='Country', suffixes=(\"_2015\", \"_2016\"))\n",
    "merged_updated_suffixes = pd.merge(left=three_2016, right=three_2015, how = 'left', on='Country', suffixes=(\"_2016\", \"_2015\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Join on Index with the Merge Function\n",
    "We've already saved four_2015 and three_2016. In this exercise, we'll use a left join to combine four_2015 and three_2016.\n",
    "\n",
    "- Predict the number of rows and columns the resulting dataframe will have. Assign the number of rows to a variable called rows and the number of columns to a variable called columns.\n",
    "- To change the join type used in merge_index to a left join, set the how parameter equal to 'left'. Save the result to merge_index_left.\n",
    "- Update rows and columns so that each contains the correct number of rows and columns in merge_index_left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.794240Z",
     "start_time": "2021-01-01T10:12:32.237Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "four_2015 = happiness2015[['Country','Happiness Rank','Year']].iloc[2:6]\n",
    "three_2016 = happiness2016[['Country','Happiness Rank','Year']].iloc[2:5]\n",
    "merge_index = pd.merge(left = four_2015,right = three_2016, left_index = True, right_index = True, suffixes = ('_2015','_2016'))\n",
    "\n",
    "merge_index_left = pd.merge(left = four_2015,right = three_2016, left_index = True, right_index = True, suffixes = ('_2015','_2016'), how=\"left\")\n",
    "rows = merge_index_left.shape[0]\n",
    "columns = merge_index_left.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Challenge: Combine Data and Create a Visualization\n",
    "We've already created a Year column in happiness2017 and renamed the Happiness.Score column to Happiness Score.\n",
    "\n",
    "- Use either the pd.concat() function or the pd.merge() function to combine happiness2015, happiness2016, and happiness2017. Assign the result to combined.\n",
    "    - Think about whether you need to combine the data horizontally or vertically in order to create a dataframe that can be grouped by year, and decide which function (pd.concat() or pd.merge()) you can use to combine the data.\n",
    "- Use the df.pivot_table() method to create a pivot table from the combined dataframe. Set Year as the index and Happiness Score as the values. Assign the result to pivot_table_combined.\n",
    "- Use the df.plot() method to create a bar chart of the results. Set the kind parameter to barh, the title to 'Mean Happiness Scores by Year', and the xlim parameter to (0,10).\n",
    "- Try to answer the following question based on the results of this exercise: Did world happiness increase, decrease, or stay about the same from 2015 to 2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T10:12:32.795532Z",
     "start_time": "2021-01-01T10:12:32.238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "happiness2017.rename(columns={'Happiness.Score': 'Happiness Score'}, inplace=True)\n",
    "\n",
    "combined = pd.concat([happiness2015, happiness2016, happiness2017])\n",
    "pivot_table_combined = combined.pivot_table(\"Happiness Score\", \"Year\")\n",
    "_ = pivot_table_combined.plot(kind=\"barh\", title=\"Mean Happiness Scores by Year\", xlim=(0,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}